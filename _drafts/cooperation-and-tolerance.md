---
layout: post
title: Cooperating with the uncooperative
excerpt: or Dissolving the paradox of tolerance.
---

I recently finished Magnus Vinding's new book, [Suffering-Focused Ethics](https://magnusvinding.com/2020/05/31/suffering-focused-ethics-defense-and-implications/), as part of our latest [EA Chicago](https://eachicago.com/) book club. As you might expect from the title, it wasn't a light read, but I found it worthwhile, and probably updated my opinion in the direction of Vinding's claim that the abolition of extreme forms of suffering should be our collective moral priority.

One surprising focus of the book was on the importance of cooperation with others who may not necessarily prioritize extreme suffering and instead favor more traditional moral frameworks, like increasing happiness or reducing inequality. In a chapter titled "We Should be Cooperative," Vinding makes the case that cooperation across value differences can result in positive-sum "moral trade," and is the optimal solution to certain game theoretic problems (drawing on Robert Alexrod's work in [The Evolution of Cooperation](https://en.wikipedia.org/wiki/The_Evolution_of_Cooperation)).

This all seems pretty reasonable, but at the same time it's a little confusing. While I don't think Vinding is advocating for unconditional cooperation (for instance, he cautions that "we should go to great lengths to avoid hostile behavior," which seems to rule out collaboration with violent extremists), it's unclear where exactly he thinks we should draw the line. The problem of determining the limits of cooperation is reminiscent of the [paradox of tolerance](https://en.wikipedia.org/wiki/Paradox_of_tolerance), introduced by Karl Popper in [The Open Society and Its Enemies](https://en.wikipedia.org/wiki/The_Open_Society_and_Its_Enemies), which gives a recursive warning against tolerating the intolerant: "unlimited tolerance must lead to the disappearance of tolerance."

But would unlimited cooperation pose a similar threat, and if so, when should we be willing to cooperate with the uncooperative?

<!--more-->
* table of contents
{: toc }

# Reframing the problem

Before addressing that question directly, let's start with a simpler one: what disposition regarding an ideology leads to the largest number of potential collaborators? Or put another way, what stance should I take on a given issue if my only goal is to maximize the number of people willing to work with me?

As an example, imagine a population filled with supporters and detractors of ideology A. Among each group there are some who are willing to cooperate with members of the opposing group, and others who are not. See the illustrative diagram below:

[![a.png]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/a.png "a"){: .center-image }]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/a.png)

Critically, if you're looking to maximize collaborators, there are only three possible subgroups from which to choose. You could support ideology A, which nets you both pro-A boxes, and 55% of the overall population. However, because those in the upper right are unwilling to work with their ideological opponents, you will lose all of the anti-A row (even those in the lower left). The inverse choice is also available, in which you oppose A at the expense of the pro-A row.

Finally, you could decline to take an exclusive position on A. In essence, this is like choosing the cooperative column at the expense of the uncooperative. Note that *the inverse of this choice is unavailable*, because the uncooperative boxes have mutually incompatible values, and can never be part of the same group.

Finding the disposition that maximizes collaborators is as simple as computing the three sums (pro-A row, anti-A row, cooperative column), and choosing the largest total. In this case, it pays to back ideology A (in largest total, in green), but this is clearly dependent on the specific values in each box.

This framing is obviously incomplete and probably cynical, in that it ignores other important factors like the relative merits of different subgroups, and the consequences of the ideology itself. But I've found it useful as an intuition pump for some otherwise mysterious behavior, as I'll try to demonstrate below.

# Examples

Let's look at a few more practical examples to help refine this framework. (Note that all of the actual numbers below are made up for illustrative purposes. I haven't seen polling data on any of these ideologies that would be sufficient to categorize  populations by cooperativeness, but I also haven't really looked.)

## Vegan restaurant

Imagine you're looking to open a new vegan restaurant, and are deciding who to hire from among the submitted resumes. Would it be better to employ only fellow vegans, or to broaden your candidate search to include omnivores as well? The cooperation diagram for this scenario might look something like the example below:

[![vegan.png]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/vegan.png "vegan"){: .center-image }]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/vegan.png)

Although the majority of applicants are vegan, the disposition that maximizes potential employees is one that is inclusive of cooperative omnivores, even at the cost of the presumably hardcore vegans in the upper-right box.

## Holocaust denial

But what about an ideology more extreme than veganism like, say, holocaust denial? While it seems obviously counterproductive to collaborate with holocaust deniers, can this intuition be quantified?

[![holocaust.png]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/holocaust.png "holocaust"){: .center-image }]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/holocaust.png)

As shown in the artificial (and likely exaggerated) data above, the optimal disposition in this case is one that prioritizes holocaust non-deniers, since even an agnostic stance would sacrifice the majority of the potential collaborators. Examples like this help explain why Popper claims "in the name of tolerance, the right to not tolerate the intolerant."

## Coinbase

A more practical example is the [recent cultural shift](https://arstechnica.com/cars/2020/10/sixty-coinbase-employees-take-buyout-offer-over-no-politics-rule/) at [Coinbase](https://www.coinbase.com/), a US-based cryptocurrency exchange. At a time when seemingly every company has felt (morally and/or financially) compelled to issue [bland corporate statements](https://www.theatlantic.com/health/archive/2020/06/brands-racism-protests-amazon-nfl-nike/612613/) in support of racial justice initiatives, Coinbase has [wholesale rejected](https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804) the notion of itself as a general-purpose political entity. Their [new culture doc](https://blog.coinbase.com/culture-at-coinbase-fe510fe9c098) even seems to explicitly choose the cooperative column, stating:

> Being inclusive also extends beyond hiring, to creating a welcoming environment for all. At work, we focus on what unites us, our mission, and not what divides us. It’s not ok to attack your colleagues, just because they have different beliefs than you. We refrain from debating issues or advocating for causes unrelated to our mission or business objectives at work because we believe it harms inclusion.

Although it's hard to avoid the aforementioned paradoxical formulations (i.e. political activists will likely not find this new environment "inclusive" or "welcoming"), this at least makes sense when thinking about how to maximize potential collaborators in the crypto space, which [skews Libertarian](https://downloads.coindesk.com/research/state-of-blockchain/2018/q3/sob2018q3-2018.pdf). A hypothetical cooperative diagram justifying Coinbase's decision might look something like this:

[![coinbase.png]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/coinbase.png "coinbase"){: .center-image }]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/coinbase.png)

In the example above, people who would prefer a more activist approach are in the minority, but could still participate in a cooperative culture by becoming more cooperative themselves. As it is, however, appeasing the apolitical majority and rejecting all workplace activism yields the largest number of potential Coinbase employees.

# Additional thoughts

So is this interesting? I'm not sure. Partly, I think I might be just rehashing Slate Star Codex's [Conflict Vs. Mistake](https://slatestarcodex.com/2018/01/24/conflict-vs-mistake/) dichotomy. The critical similarity is that, while mistake theorists with different ideologies can sometimes work together, conflict theorists likely cannot. This may help to explain why we so rarely see collaborations across the prongs of the [political horseshoe](https://en.wikipedia.org/wiki/Horseshoe_theory), as shown at the top of the political compass diagram below:

[![political-compass.png]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/political-compass.png "political-compass"){: .center-image }]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/political-compass.png)

Another potential drawback to the toy model is that not all collaborators are of equal value. In the vegan restaurant example, the hardcore vegans might bring enthusiasm enough to outweigh their numerical disadvantage. This kind of naïve maximization is also vulnerable to [Goddhart's law](https://en.wikipedia.org/wiki/Goodhart%27s_law), in which the majority ideology has a perverse incentive to become less cooperative:

[![b.png]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/b.png "b"){: .center-image }]({{ site.baseurl }}/assets/images/cooperation-and-tolerance/b.png)

In the example above, believers in ideology B are in a 55/45 majority, but the optimal disposition in the diagram on the left is still cooperation. However, if the group can internally coordinate and signal sufficient uncooperativeness, they can shift the maximum total to their row, as shown on the right. This implies that majorities may be incentivized to become less cooperative as their (perceived?) numerical advantage increases. And it rings true to me, having observed similar real-world dynamics. It's also a warning against uncooperative minorities attempting to impose their preferences on a larger population, like in the Coinbase example above.

A final thought: ties should go to collaboration/tolerance. For starters, this is just more virtuous, but it's also probably more robust to things like value drift, multi-dimensional ideologies, and iterated scenarios.
